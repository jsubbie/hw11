{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import os \n",
    "import pandas as pd \n",
    "import requests\n",
    "import tweepy\n",
    "import time \n",
    "from bs4 import BeautifulSoup as BS\n",
    "from splinter import Browser\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#set executable path for chromedriver /// Note: on MacOS don't use .exe file extension \n",
    "executable_path = {'executable_path': 'chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'April  6, 2018Bound for Mars: Countdown to First Interplanetary Launch from CaliforniaOn May 5, millions of Californians may witness the historic first interplanetary launch from Americaâ€™s West Coast.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mars News \n",
    "\n",
    "# base URL\n",
    "url = \"https://mars.nasa.gov/news/\"\n",
    "\n",
    "# visit the site \n",
    "browser.visit(url)\n",
    "\n",
    "# create BS object for the news \n",
    "html = browser.html\n",
    "news_soup = BS(html, \"html.parser\")\n",
    "\n",
    "# Use BS to locate first article and pull title \n",
    "news_title = news_soup.body.find('div', class_=\"content_title\").text\n",
    "news_p = news_soup.body.find('div', class_=\"list_text\").text\n",
    "\n",
    "# print it up pretty \n",
    "\n",
    "news_title\n",
    "news_p\n",
    "                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.jpl.nasa.gov//spaceimages/images/largesize/PIA16919_hires.jpg'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mars Images \n",
    "\n",
    "#get url for images \n",
    "browser = Browser('chrome', headless = False)\n",
    "\n",
    "# img url \n",
    "jpl_img = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "\n",
    "# visit site \n",
    "browser.visit(jpl_img)\n",
    "\n",
    "# find button and click it to search \n",
    "browser.click_link_by_partial_text('FULL IMAGE')\n",
    "# time.sleep(5) /// use sleep from the time function if you're worried about the getting booted from the site \n",
    "\n",
    "# find button \"more info\" button \n",
    "\n",
    "browser.click_link_by_partial_text('more info')\n",
    "\n",
    "# define img_html by results of \"more info\" button click \n",
    "\n",
    "img_html = browser.html\n",
    "\n",
    "# create a soup object from the html\n",
    "mars_img_soup = BS(img_html, \"html.parser\")\n",
    "img_path = mars_img_soup.find('figure', class_='lede').find('img')['src']\n",
    "featured_img_url = \"https://www.jpl.nasa.gov/\" + img_path\n",
    "\n",
    "featured_img_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sol 2016 (April 08, 2018), Sunny, high -9C/15F, low -73C/-99F, pressure at 7.18 hPa, daylight 05:28-17:21'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mars weather from Twitter\n",
    "\n",
    "# grab latest weather tweet from Twitter /// becuase the url below links directly to the Mars Weather Twitter \n",
    "# there is no need to perform any advanced API requests. \n",
    "\n",
    "# base URL\n",
    "weather = \"https://twitter.com/marswxreport?lang=en\"\n",
    "\n",
    "#visit site\n",
    "browser.visit(weather)\n",
    "\n",
    "# store result of visit as a variable  \n",
    "weather_html = browser.html\n",
    "\n",
    "# create BS object for weather info \n",
    "weather_soup = BS(weather_html, \"html.parser\")\n",
    "\n",
    "# scrape that data, son. /// be sure to add \".strip()\" in order to clean up the output \n",
    "mars_weather = weather_soup.find('div', class_=\"js-tweet-text-container\").text.strip()\n",
    "\n",
    "# print it pretty \n",
    "mars_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Equatorial Diameter:</td>\n",
       "      <td>6,792 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polar Diameter:</td>\n",
       "      <td>6,752 km</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mass:</td>\n",
       "      <td>6.42 x 10^23 kg (10.7% Earth)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moons:</td>\n",
       "      <td>2 (Phobos &amp; Deimos)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Orbit Distance:</td>\n",
       "      <td>227,943,824 km (1.52 AU)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            description                          value\n",
       "0  Equatorial Diameter:                       6,792 km\n",
       "1       Polar Diameter:                       6,752 km\n",
       "2                 Mass:  6.42 x 10^23 kg (10.7% Earth)\n",
       "3                Moons:            2 (Phobos & Deimos)\n",
       "4       Orbit Distance:       227,943,824 km (1.52 AU)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mars Facts \n",
    "\n",
    "#Use pandas to read and render table \n",
    "mars_facts_url = 'https://space-facts.com/mars/'\n",
    "tables_df = pd.read_html(mars_facts_url)[0] #remember to 0-index the df\n",
    "tables_df.columns = [\"description\", \"value\"]\n",
    "\n",
    "tables_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cerberus Hemisphere Enhanced\n",
      "https://astrogeology.usgs.gov/cache/images/cfa62af2557222a02478f1fcd781d445_cerberus_enhanced.tif_full.jpg\n",
      "Schiaparelli Hemisphere Enhanced\n",
      "https://astrogeology.usgs.gov/cache/images/3cdd1cbf5e0813bba925c9030d13b62e_schiaparelli_enhanced.tif_full.jpg\n",
      "Syrtis Major Hemisphere Enhanced\n",
      "https://astrogeology.usgs.gov/cache/images/ae209b4e408bb6c3e67b6af38168cf28_syrtis_major_enhanced.tif_full.jpg\n",
      "Valles Marineris Hemisphere Enhanced\n",
      "https://astrogeology.usgs.gov/cache/images/7cf2da4bf549ed01c17f206327be4db7_valles_marineris_enhanced.tif_full.jpg\n"
     ]
    }
   ],
   "source": [
    "#Visit website using splinter\n",
    "usgs_url = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "\n",
    "# visit site \n",
    "\n",
    "browser.visit(usgs_url)\n",
    "\n",
    "# create BS object to find the content from the usgs url \n",
    "\n",
    "usgs_html = browser.html\n",
    "hemisphere_soup = BS(usgs_html, \"html.parser\")\n",
    "\n",
    "# create object that finds the divs and classes for the images we are looking for /// Note: I wonder if there is \n",
    "# a way to perform a multi-parameter search without having to make it a two step process... for the time being, this \n",
    "# seems to be the easiest way to do this. \n",
    "\n",
    "hemisphere_results= hemisphere_soup.find(\"div\",class_=\"collapsible results\").find_all(\"div\",class_=\"item\")\n",
    "\n",
    "#Create empty list to hold urls\n",
    "hemisphere_img_urls = []\n",
    "\n",
    "# Loop through hemisphere \n",
    "\n",
    "for item in hemisphere_results:\n",
    "        # find img title \n",
    "        title = item.find(\"h3\").text\n",
    "        \n",
    "        # alright... now we have to \"click\" on the thumbbnail image in order to get the large image... \n",
    "        url=\"https://astrogeology.usgs.gov\"+item.find(\"a\",class_=\"itemLink product-item\").get(\"href\")\n",
    "        browser.visit(url)\n",
    "                \n",
    "        # so.. we need to create another BS object in order to find the full URL of the large image \n",
    "        html = browser.html\n",
    "        img_soup = BS(html,\"html.parser\")        \n",
    "        \n",
    "        # Save yourself a ton of trial and error and define the partial link for the large image first. /// \n",
    "        # this (apparently) is easier than to try to get it all done in one shot which errors out every time. \n",
    "        p_link = img_soup.find(\"div\",class_=\"wide-image-wrapper\").find(\"img\",class_=\"wide-image\").get(\"src\")\n",
    "        \n",
    "        # so here's where it all comes togther --- merge the general site url and the img p_link\n",
    "        img_url = \"https://astrogeology.usgs.gov\"+p_link\n",
    "        \n",
    "        # Append the results to the aforementioned list \n",
    "        hemisphere_image_urls.append({\"title\":title,\"img_url\":img_url,\"hemisphere_url\":url})\n",
    "        \n",
    "        # print it up all pretty like \n",
    "        print(title)\n",
    "        print(img_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above is an excellent example of a multi-tiered scrape. As with most things, start broad and then winnow \n",
    "# down to the specifics. /// Always be sure to print it up all pretty. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
